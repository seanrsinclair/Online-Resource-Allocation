{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waterfilling Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../../functions')\n",
    "import importlib\n",
    "import numpy as np\n",
    "import nbformat\n",
    "import plotly.express\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import scipy.optimize as optimization\n",
    "import food_bank_functions\n",
    "import food_bank_bayesian\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from food_bank_functions import *\n",
    "from food_bank_bayesian import *\n",
    "import time\n",
    "importlib.reload(food_bank_functions)\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "../../data/gaussian/vals_15_var_3.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7bb120763761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../data/gaussian/vals_15_var_3.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msupport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../data/gaussian/support_15_var_3.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    614\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    615\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: ../../data/gaussian/vals_15_var_3.csv not found."
     ]
    }
   ],
   "source": [
    "vals = np.loadtxt('../../data/gaussian/vals_15_var_3.csv', delimiter=\",\")\n",
    "support = np.loadtxt('../../data/gaussian/support_15_var_3.csv', delimiter=\",\")\n",
    "var = variance(support, vals)\n",
    "med = median(support, vals)\n",
    "print(med)\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vals)\n",
    "print(support)\n",
    "vals[0] = vals[0] + (1 - np.sum(vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(support, vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6\n",
    "sorted_distribution = support\n",
    "weights = vals\n",
    "expected_demand = np.dot(vals, support)\n",
    "print(expected_demand)\n",
    "max_budget = n * expected_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_demands = np.random.choice(size=n, a=sorted_distribution, p=vals)\n",
    "print(group_demands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(waterfilling_waste(group_demands, max_budget))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(greedy(group_demands, max_budget))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(constant_threshold(group_demands,max_budget,expected_demand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(waterfilling_proportional_remaining(group_demands, max_budget))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(waterfilling_et_waste([expected_demand for x in range(n)],group_demands,max_budget))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(waterfilling_et_full_waste([expected_demand for x in range(n)],group_demands,max_budget))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(waterfilling_hope_waste_iid(weights, sorted_distribution, group_demands, max_budget))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weights)\n",
    "print(sorted_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(waterfilling_hope_full_waste_iid(weights, sorted_distribution, group_demands, max_budget))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_min_heuristic(group_demands, [med for x in range(n)], [expected_demand for x in range(n)], [var for x in range(n)], max_budget))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying Number of Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at scaling with n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n = 100\n",
    "num_iterations = 1000\n",
    "print(weights)\n",
    "print(sorted_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_waterfilling_threshold = np.zeros(max_n+1)\n",
    "num_iterations = 1000\n",
    "for i in np.arange(2,max_n+1):\n",
    "    for _ in range(num_iterations):\n",
    "        budget = i * 15.\n",
    "        demands = np.random.choice(size=i, a=support, p=vals)\n",
    "        opt = waterfilling_waste(demands, budget)\n",
    "        expected_waterfilling_threshold[i] += (1/num_iterations)*max(opt)\n",
    "print(expected_waterfilling_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'NumGroups':[], 'Norm':[], 'ET-Online':[],'Hope-Online':[], 'Adapt-Threshold':[], 'Threshold':[], 'Expected-Filling':[], 'Greedy':[], 'ET-Full':[], 'Hope-Full':[], 'Max-Min':[]}\n",
    "num_iterations = 1000\n",
    "for n in np.arange(2,max_n+1,1):\n",
    "    n = max(int(n),1)\n",
    "    group_expected_demands = np.zeros(n) + np.dot(weights, sorted_distribution)\n",
    "    group_median_demands = np.zeros(n) + med\n",
    "    group_variance = np.zeros(n) + var\n",
    "    budget = n*expected_demand\n",
    "    print(n)\n",
    "    for i in range(num_iterations):\n",
    "        data_dict['NumGroups'].append(n)\n",
    "\n",
    "        \n",
    "        group_demands = np.random.choice(size=n, a=support, p=vals)\n",
    "        opt = waterfilling_waste(group_demands,budget)\n",
    "        \n",
    "        print('new round')\n",
    "        \n",
    "        hope_sol = waterfilling_hope_waste_iid(weights, sorted_distribution, group_demands, budget)\n",
    "        print(hope_sol)\n",
    "        hope_full_sol = waterfilling_hope_full_waste_iid(weights, sorted_distribution, group_demands, budget)\n",
    "        print(hope_full_sol)\n",
    "        dynamic = waterfilling_et_waste(group_expected_demands,group_demands,budget)\n",
    "        et_full = waterfilling_et_full_waste(group_expected_demands, group_demands, budget)\n",
    "        proportional_threshold = waterfilling_proportional_remaining(group_demands, budget)\n",
    "        greed_sol = greedy(group_demands,budget)\n",
    "        threshold = constant_threshold(group_demands,budget,expected_demand)\n",
    "        expect_threshold = constant_threshold(group_demands, budget, expected_waterfilling_threshold[n])\n",
    "        max_min_heuristic_sol = max_min_heuristic(group_demands, group_median_demands, group_expected_demands, group_variance, budget)\n",
    "\n",
    "\n",
    "        \n",
    "        data_dict['Norm'].append('L1')\n",
    "        data_dict['Hope-Online'].append(np.sum(np.absolute(opt - hope_sol)))\n",
    "        data_dict['ET-Online'].append(np.sum(np.absolute(opt-dynamic)))\n",
    "        data_dict['Adapt-Threshold'].append(np.sum(np.absolute(opt - proportional_threshold)))\n",
    "        data_dict['Greedy'].append(np.sum(np.absolute(opt-greed_sol)))\n",
    "        data_dict['Threshold'].append(np.sum(np.absolute(opt-threshold)))\n",
    "        data_dict['ET-Full'].append(np.sum(np.absolute(opt-et_full)))\n",
    "        data_dict['Hope-Full'].append(np.sum(np.absolute(opt-hope_full_sol)))\n",
    "        data_dict['Expected-Filling'].append(np.sum(np.absolute(opt - expect_threshold)))\n",
    "        data_dict['Max-Min'].append(np.sum(np.absolute(opt - max_min_heuristic_sol)))\n",
    "        \n",
    "        data_dict['NumGroups'].append(n)\n",
    "        data_dict['Norm'].append('Linf')\n",
    "        data_dict['Hope-Online'].append(np.max(np.absolute(opt - hope_sol)))\n",
    "        data_dict['ET-Online'].append(np.max(np.absolute(opt-dynamic)))\n",
    "        data_dict['Adapt-Threshold'].append(np.max(np.absolute(opt - proportional_threshold)))\n",
    "        data_dict['Greedy'].append(np.max(np.absolute(opt-greed_sol)))\n",
    "        data_dict['Threshold'].append(np.max(np.absolute(opt-threshold)))\n",
    "        data_dict['ET-Full'].append(np.max(np.absolute(opt-et_full)))\n",
    "        data_dict['Hope-Full'].append(np.max(np.absolute(opt-hope_full_sol)))\n",
    "        data_dict['Expected-Filling'].append(np.max(np.absolute(opt - expect_threshold)))\n",
    "        data_dict['Max-Min'].append(np.max(np.absolute(opt - max_min_heuristic_sol)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_dict).melt(id_vars=[\"NumGroups\", 'Norm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos_to_exclude = ['Threshold','Expected-Filling']\n",
    "data_to_graph = (df[~df.variable.isin(algos_to_exclude)]\n",
    "                 .rename({'variable': 'Algorithm'}, axis = 1)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('PaperDoubleFig.mplstyle.txt')\n",
    "# Make some style choices for plotting \n",
    "colorWheel =['#2bd1e5',\n",
    "            '#281bf5',\n",
    "             '#db1bf5',\n",
    "             '#F5CD1B',\n",
    "            '#FF5733','#9cf51b',]\n",
    "dashesStyles = [[3,1],\n",
    "            [2,1,10,1],\n",
    "            [4, 1, 1, 1, 1, 1],[1000,1],[8,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_graph = data_to_graph.sort_values(by='Algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_markers = ('o', 'v', '^', '<', '>', '8', 's', 'p', '*', 'h', 'H', 'D', 'd', 'P', 'X')\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title('Gaussian L1')\n",
    "dash_styles = [\"\",\n",
    "               (4, 1.5),\n",
    "               (1, 1),\n",
    "               (3, 1, 1.5, 1),\n",
    "               (5, 1, 1, 1),\n",
    "               (5, 1, 2, 1, 2, 1),\n",
    "               (2, 2, 3, 1.5),\n",
    "               (1, 2.5, 3, 1.2)]\n",
    "\n",
    "sns.lineplot(x='NumGroups', y='value', hue='Algorithm', style = 'Algorithm', dashes = dash_styles, data=data_to_graph[data_to_graph.Norm == 'L1'], ci = None)\n",
    "plt.xlabel('Number of Agents')\n",
    "plt.ylabel('Distance')\n",
    "plt.title('Maximum Difference Between OPT and ALG Allocations')\n",
    "plt.savefig('linf.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_graph.Algorithm.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_graph.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('scale_with_n.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.variable == 'Weights'].head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_markers = ('o', 'v', '^', '<', '>', '8', 's', 'p', '*', 'h', 'H', 'D', 'd', 'P', 'X')\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title('Gaussian L1')\n",
    "sns.lineplot(x='NumGroups', y='value', hue='variable', data=df[df.Norm == 'L1'], ci = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'Group':[], 'hope_Full':[], 'hope_Online':[],'et_Full':[], 'et_Online':[], 'True':[], 'Max_Min_Heuristic':[]}\n",
    "num_iterations = 1000\n",
    "\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    max_n = 100\n",
    "    \n",
    "    weights = np.loadtxt('../../data/gaussian/vals_15_var_3.csv', delimiter=\",\")\n",
    "    sorted_support = np.loadtxt('../../data/gaussian/support_15_var_3.csv', delimiter=\",\")\n",
    "    \n",
    "    expected_demands = [expected_demand for x in range(max_n)]\n",
    "    median_demands = [med for _ in range(max_n)]\n",
    "    variance = [var for _ in range(max_n)]\n",
    "    \n",
    "    # print(weights)\n",
    "    # print(sorted_support)\n",
    "    # print(expected_demands)\n",
    "    max_budget = max_n*expected_demand\n",
    "    \n",
    "    \n",
    "    \n",
    "    group_demands = np.random.choice(size=max_n, a=sorted_support, p=weights).astype(np.float)\n",
    "    print('Demands for experiment:' + str(group_demands))   \n",
    "    \n",
    "    et_full = np.copy(expected_demands)\n",
    "    et_online = np.sort(np.copy(expected_demands))\n",
    "    \n",
    "    et_online_budget = max_budget\n",
    "    hope_online_budget = max_budget\n",
    "\n",
    "    hope_online_support = np.copy(sorted_support)\n",
    "    hope_online_vals = np.copy(weights)*max_n\n",
    "    \n",
    "    hope_full_support = np.copy(sorted_support)\n",
    "    hope_full_vals = np.copy(weights)*max_n\n",
    "    print('start')\n",
    "    print(hope_full_vals)\n",
    "    print(np.sum(hope_full_vals))\n",
    "    max_min_budget = max_budget\n",
    "    min_fill = 1\n",
    "    \n",
    "    for n in range(max_n):\n",
    "        # Solve for the various waterfilling levels\n",
    "        data_dict['Group'].append(n)\n",
    "        \n",
    "        # Adds on the true waterfilling level\n",
    "        data_dict['True'].append(max(waterfilling_sorted(np.sort(np.copy(group_demands)), max_budget)))\n",
    "        \n",
    "        \n",
    "        # et_Full\n",
    "        \n",
    "        # Replaces current town's demand with realized demand\n",
    "        et_full[n] = group_demands[n]\n",
    "        # Sorts demands\n",
    "        et_full_sorted = np.sort(np.copy(et_full))\n",
    "        # Appends maximum allocation based on full demand with full budget\n",
    "        data_dict['et_Full'].append(max(waterfilling_sorted(et_full_sorted, max_budget)))\n",
    "            \n",
    "            \n",
    "        # et_Online\n",
    "        \n",
    "        # Removes expected demand for current agent from list\n",
    "        et_online = delete_sorted(et_online, expected_demands[n])\n",
    "        \n",
    "        # adds in the demand for current location\n",
    "        new_sorted_list, index = insert_sorted(et_online, group_demands[n])\n",
    "        tmp_sol = waterfilling_sorted(new_sorted_list, et_online_budget)\n",
    "        data_dict['et_Online'].append(max(tmp_sol))\n",
    "        # subtracts off the allocation for the next round\n",
    "        et_online_budget -= min(tmp_sol[index], et_online_budget, group_demands[n])\n",
    "        \n",
    "        \n",
    "        # hope_Full\n",
    "        \n",
    "        # Updating the weights for the observed group\n",
    "        obs_demand = group_demands[n]\n",
    "        \n",
    "        index = np.argmin(np.abs(hope_full_support - obs_demand))\n",
    "        hope_full_vals -= weights\n",
    "        hope_full_vals[index] += 1\n",
    "        \n",
    "        data_dict['hope_Full'].append(max(waterfilling_sorted_weights(hope_full_support, hope_full_vals, max_budget)))\n",
    "        \n",
    "        \n",
    "#         if n == max_n - 1:\n",
    "#             print(max(waterfilling_sorted(np.sort(np.copy(group_demands)), max_budget)))\n",
    "#             print(max(waterfilling_sorted_weights(hope_full_support, hope_full_vals, max_budget)))\n",
    "#             print(hope_full_vals)\n",
    "        \n",
    "        # hope_Online\n",
    "        obs_demand = group_demands[n]\n",
    "        \n",
    "        index = np.argmin(np.abs(hope_online_support - obs_demand))\n",
    "        hope_online_vals -= weights\n",
    "        hope_online_vals[index] += 1        \n",
    "        \n",
    "        \n",
    "        tmp_sol = waterfilling_sorted_weights(hope_online_support, hope_online_vals, hope_online_budget)\n",
    "        hope_online_budget -= min(obs_demand, hope_online_budget, tmp_sol[index])\n",
    "        \n",
    "        hope_online_vals[index] -= 1\n",
    "        data_dict['hope_Online'].append(max(tmp_sol))\n",
    "        \n",
    "        # Max_Min\n",
    "        \n",
    "        if n == max_n - 1:\n",
    "            data_dict['Max_Min_Heuristic'].append(min(max_min_budget, group_demands[n]))\n",
    "        else:\n",
    "            delta = (median_demands[n] - median_demands[n+1]) / ((1/2)* (median_demands[n] + median_demands[n+1]))\n",
    "            budget_portion = max_min_budget * (expected_demands[n] + expected_demands[n+1]) / np.sum(expected_demands[n:])\n",
    "            heuristic_threshold = budget_portion * (group_demands[n] / (group_demands[n] + median_demands[n+1] + delta * np.sqrt(variance[n+1])))\n",
    "            allocation = min(heuristic_threshold, min_fill*group_demands[n], max_min_budget)\n",
    "            data_dict['Max_Min_Heuristic'].append(heuristic_threshold)\n",
    "            \n",
    "            if allocation / group_demands[n] <= min_fill:\n",
    "                min_fill = allocation / group_demands[n]\n",
    "            max_min_budget -= allocation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(data_dict['True'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_dict).melt(id_vars=\"Group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('comparison_of_waterfilling_levels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.lineplot(x='Group', y='value', style='variable', hue = 'variable', data=df)\n",
    "plt.title('Estimated Waterfilling Levels')\n",
    "plt.xlabel('Estimated Level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Fairness Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 1000\n",
    "weights = np.loadtxt('../../data/gaussian/vals_15_var_3.csv', delimiter=\",\")\n",
    "sorted_distribution = np.loadtxt('../../data/gaussian/support_15_var_3.csv', delimiter=\",\")\n",
    "expected_demand = np.dot(weights, sorted_distribution)\n",
    "n=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = np.arange(n)\n",
    "group_expected_demands = np.zeros(n) + expected_demand\n",
    "budget = expected_demand*n\n",
    "score_hope_online = np.zeros((n,num_iterations))\n",
    "score_hope_full = np.zeros((n,num_iterations))\n",
    "score_et_online = np.zeros((n,num_iterations))\n",
    "score_et_full = np.zeros((n,num_iterations))\n",
    "score_greedy = np.zeros((n,num_iterations))\n",
    "score_adapt_threshold = np.zeros((n,num_iterations))\n",
    "score_fixed_threshold = np.zeros((n,num_iterations))\n",
    "score_expect_threshold = np.zeros((n, num_iterations))\n",
    "score_max_min = np.zeros((n, num_iterations))\n",
    "\n",
    "# 8 different algorithms\n",
    "run_time = np.zeros((6, num_iterations))\n",
    "env = np.zeros((9,num_iterations))\n",
    "po = np.zeros((9,num_iterations))\n",
    "prop = np.zeros((9,num_iterations))\n",
    "linf = np.zeros((9,num_iterations))\n",
    "l1 = np.zeros((9, num_iterations))\n",
    "max_min = np.zeros((9, num_iterations))\n",
    "for i in range(num_iterations):\n",
    "    budget = n*np.dot(weights, sorted_distribution)\n",
    "\n",
    "        \n",
    "    group_demands = np.random.choice(size=n, a=sorted_distribution, p=weights)\n",
    "    group_median_demands = np.zeros(n) + med\n",
    "    group_variance = np.zeros(n) + var\n",
    "      \n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    opt = waterfilling_waste(group_demands,budget)\n",
    "    run_time[0,i] = time.perf_counter() - start\n",
    "       \n",
    "    start = time.perf_counter()\n",
    "    hope_sol = waterfilling_hope_waste_iid(weights, sorted_distribution, group_demands, budget)\n",
    "    run_time[1,i] = time.perf_counter() - start\n",
    "     \n",
    "    start = time.perf_counter()\n",
    "    hope_full_sol = waterfilling_hope_full_waste_iid(weights, sorted_distribution, group_demands, budget)\n",
    "    run_time[2,i] = time.perf_counter() - start\n",
    "     \n",
    "    start = time.perf_counter()\n",
    "    dynamic = waterfilling_et_waste(group_expected_demands,group_demands,budget)\n",
    "    run_time[3,i] = time.perf_counter() - start\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    et_full = waterfilling_et_full_waste(group_expected_demands, group_demands, budget)\n",
    "    run_time[4, i] = time.perf_counter() - start\n",
    " \n",
    "    proportional_threshold = waterfilling_proportional_remaining(group_demands, budget)\n",
    "    greedy_sol = greedy(group_demands,budget)\n",
    "    threshold = constant_threshold(group_demands,budget,expected_demand)\n",
    "    expect_threshold = constant_threshold(group_demands, budget, expected_waterfilling_threshold[n])\n",
    "    \n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    max_min_heuristic_sol = max_min_heuristic(group_demands, group_median_demands, group_expected_demands, group_variance, budget)\n",
    "    run_time[5,i] = time.perf_counter()- start\n",
    "    # comparing hope_online\n",
    "    \n",
    "    score_hope_online[:,i] = opt - hope_sol\n",
    "    env[0,i] = max(0,np.amax(envy_utility(hope_sol,group_demands)))\n",
    "    po[0,i] = excess(hope_sol,budget)\n",
    "    prop[0,i] = np.amax(proportionality_utility(hope_sol,group_demands,budget))\n",
    "    max_min[0,i] = np.min(utility_ratio(hope_sol, group_demands, budget))\n",
    "    linf[0,i] = np.amax(np.abs(score_hope_online[:,i]))\n",
    "    l1[0,i] = np.sum(np.abs(score_hope_online[:,i]))\n",
    "    \n",
    "    \n",
    "    # comparing hope_full\n",
    "    \n",
    "    score_hope_full[:,i] = opt - hope_full_sol\n",
    "    env[1,i] = max(0,np.amax(envy_utility(hope_full_sol,group_demands)))\n",
    "    po[1,i] = excess(hope_full_sol,budget)\n",
    "    prop[1,i] = np.amax(proportionality_utility(hope_full_sol,group_demands,budget))\n",
    "    max_min[1,i] = np.min(utility_ratio(hope_full_sol, group_demands, budget))\n",
    "    linf[1,i] = np.amax(np.abs(score_hope_full[:,i]))\n",
    "    l1[1,i] = np.sum(np.abs(score_hope_full[:,i]))   \n",
    "    \n",
    "    # comparing et_online\n",
    "    \n",
    "    score_et_online[:,i] = opt - dynamic\n",
    "    env[2,i] = max(0,np.amax(envy_utility(dynamic,group_demands)))\n",
    "    po[2,i] = excess(dynamic,budget)\n",
    "    prop[2,i] = np.amax(proportionality_utility(dynamic,group_demands,budget))\n",
    "    max_min[2,i] = np.min(utility_ratio(dynamic, group_demands, budget))\n",
    "    linf[2,i] = np.amax(np.abs(score_et_online[:,i]))\n",
    "    l1[2,i] = np.sum(np.abs(score_et_online[:,i]))       \n",
    "    \n",
    "    # comparing et_full\n",
    "    \n",
    "    score_et_full[:,i] = opt - et_full\n",
    "    env[3,i] = max(0,np.amax(envy_utility(et_full,group_demands)))\n",
    "    po[3,i] = excess(et_full,budget)\n",
    "    prop[3,i] = np.amax(proportionality_utility(et_full,group_demands,budget))\n",
    "    max_min[3,i] = np.min(utility_ratio(et_full, group_demands, budget))\n",
    "    linf[3,i] = np.amax(np.abs(score_et_full[:,i]))\n",
    "    l1[3,i] = np.sum(np.abs(score_et_full[:,i]))     \n",
    "    \n",
    "    # comparing greedy\n",
    "    \n",
    "    score_greedy[:,i] = opt - greedy_sol\n",
    "    env[4,i] = max(0,np.amax(envy_utility(greedy_sol,group_demands)))\n",
    "    po[4,i] = excess(greedy_sol,budget)\n",
    "    prop[4,i] = np.amax(proportionality_utility(greedy_sol,group_demands,budget))\n",
    "    max_min[4,i] = np.min(utility_ratio(greedy_sol, group_demands, budget))\n",
    "    linf[4,i] = np.amax(np.abs(score_greedy[:,i]))\n",
    "    l1[4,i] = np.sum(np.abs(score_greedy[:,i]))     \n",
    "    \n",
    "    # comparing fixed_threshold\n",
    "    \n",
    "    score_fixed_threshold[:,i] = opt - threshold\n",
    "    env[5,i] = max(0,np.amax(envy_utility(threshold,group_demands)))\n",
    "    po[5,i] = excess(threshold,budget)\n",
    "    prop[5,i] = np.amax(proportionality_utility(threshold,group_demands,budget))\n",
    "    max_min[5,i] = np.min(utility_ratio(threshold, group_demands, budget))\n",
    "    linf[5,i] = np.amax(np.abs(score_fixed_threshold[:,i]))\n",
    "    l1[5,i] = np.sum(np.abs(score_fixed_threshold[:,i]))  \n",
    "    \n",
    "    # comparing adaptive_threshold\n",
    "    \n",
    "    score_adapt_threshold[:,i] = opt - proportional_threshold\n",
    "    env[6,i] = max(0,np.amax(envy_utility(proportional_threshold,group_demands)))\n",
    "    po[6,i] = excess(proportional_threshold,budget)\n",
    "    prop[6,i] = np.amax(proportionality_utility(proportional_threshold,group_demands,budget))\n",
    "    max_min[6,i] = np.min(utility_ratio(proportional_threshold, group_demands, budget))\n",
    "    linf[6,i] = np.amax(np.abs(score_adapt_threshold[:,i]))\n",
    "    l1[6,i] = np.sum(np.abs(score_adapt_threshold[:,i]))   \n",
    "    \n",
    "    # comparing expected_threshold\n",
    "    \n",
    "    score_expect_threshold[:,i] = opt - expect_threshold\n",
    "    env[7,i] = max(0,np.amax(envy_utility(expect_threshold,group_demands)))\n",
    "    po[7,i] = excess(expect_threshold,budget)\n",
    "    prop[7,i] = np.amax(proportionality_utility(expect_threshold,group_demands,budget))\n",
    "    max_min[7,i] = np.min(utility_ratio(expect_threshold, group_demands, budget))\n",
    "    linf[7,i] = np.amax(np.abs(score_expect_threshold[:,i]))\n",
    "    l1[7,i] = np.sum(np.abs(score_expect_threshold[:,i]))       \n",
    "\n",
    "    # comparing max_min_heurstic\n",
    "    \n",
    "    score_max_min[:,i] = opt - max_min_heuristic_sol\n",
    "    env[8,i] = max(0,np.amax(envy_utility(max_min_heuristic_sol,group_demands)))\n",
    "    po[8,i] = excess(max_min_heuristic_sol,budget)\n",
    "    prop[8,i] = np.amax(proportionality_utility(max_min_heuristic_sol,group_demands,budget))\n",
    "    max_min[8,i] = np.min(utility_ratio(max_min_heuristic_sol, group_demands, budget))\n",
    "    linf[8,i] = np.amax(np.abs(score_max_min[:,i]))\n",
    "    l1[8,i] = np.sum(np.abs(score_max_min[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_hope_online = np.average(score_hope_online, axis=1)\n",
    "score_hope_full = np.average(score_hope_full, axis=1)\n",
    "score_et_online = np.average(score_et_online, axis=1)\n",
    "score_et_full = np.average(score_et_full, axis=1)\n",
    "score_greedy = np.average(score_greedy, axis=1)\n",
    "score_adapt_threshold = np.average(score_adapt_threshold, axis=1)\n",
    "score_fixed_threshold = np.average(score_fixed_threshold, axis=1)\n",
    "score_expect_threshold = np.average(score_expect_threshold, axis=1)\n",
    "score_max_min = np.average(score_max_min, axis=1)\n",
    "\n",
    "env_std = np.std(env, axis=1)\n",
    "po_std = np.average(po, axis=1)\n",
    "prop_std = np.average(prop, axis=1)\n",
    "linf_std = np.average(linf, axis=1)\n",
    "max_min_std = np.average(max_min, axis=1)\n",
    "l1_std = np.average(l1, axis=1)\n",
    "env = np.average(env,axis=1)\n",
    "po = np.average(po,axis=1)\n",
    "prop = np.average(prop,axis=1)\n",
    "linf = np.average(linf,axis=1)\n",
    "l1 = np.average(l1, axis=1)\n",
    "max_min = np.average(max_min, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(po)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hope_online, hope_full, et_online, et_full, greedy, fixed_threshold, adaptive_threshold, expected_threshold, max_min')\n",
    "print('envy:')\n",
    "print(env)\n",
    "print(env_std * 1.96 / np.sqrt(num_iterations))\n",
    "print('po')\n",
    "print(po)\n",
    "print(po_std * 1.96 / np.sqrt(num_iterations))\n",
    "print('prop')\n",
    "print(prop)\n",
    "print(prop_std * 1.96 / np.sqrt(num_iterations))\n",
    "print('sum')\n",
    "print(env+po+prop)\n",
    "print('max_min')\n",
    "print(max_min)\n",
    "print(max_min_std * 1.96 / np.sqrt(num_iterations))\n",
    "print('linf')\n",
    "print(linf)\n",
    "print(linf_std * 1.96 / np.sqrt(num_iterations))\n",
    "print('l1')\n",
    "print(l1)\n",
    "print(l1_std * 1.96 / np.sqrt(num_iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.average(run_time, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'Agent':np.arange(n), 'Hope-Full': score_hope_online, 'Hope-Online':score_hope_full, 'ET-Online':score_et_online, 'ET-Full':score_et_full, 'Greedy':score_greedy, 'Adapt-Threshold': score_adapt_threshold, 'Fixed-Threshold': score_fixed_threshold, 'Expect-Threshold':score_expect_threshold, 'Max-Min':score_max_min}\n",
    "df_uniform = pd.DataFrame(data_dict).melt(id_vars=\"Agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniform.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniform.to_csv('fairness_group_by_group.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('PaperDoubleFig.mplstyle.txt')\n",
    "# Make some style choices for plotting \n",
    "colorWheel =['#2bd1e5',\n",
    "            '#281bf5',\n",
    "             '#db1bf5',\n",
    "             '#F5CD1B',\n",
    "            '#FF5733','#9cf51b',]\n",
    "dashesStyles = [[3,1],\n",
    "            [2,1,10,1],\n",
    "            [4, 1, 1, 1, 1, 1],[1000,1],[8,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos_to_exclude = ['Fixed-Threshold', 'Expect-Threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_graph = (df_uniform[~df_uniform.variable.isin(algos_to_exclude)]\n",
    "                 .rename({'variable': 'Algorithm'}, axis = 1)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_graph.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_graph = data_to_graph.sort_values(by='Algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_markers = ('o', 'v', '^', '<', '>', '8', 's', 'p', '*', 'h', 'H', 'D', 'd', 'P', 'X')\n",
    "dash_styles = [\"\",\n",
    "               (4, 1.5),\n",
    "               (1, 1),\n",
    "               (3, 1, 1.5, 1),\n",
    "               (5, 1, 1, 1),\n",
    "               (5, 1, 2, 1, 2, 1),\n",
    "               (2, 2, 3, 1.5),\n",
    "               (1, 2.5, 3, 1.2)]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "line = ['-', '--', '-.', ':', 'None', ' ', '', 'solid', 'dashdot']\n",
    "plt.title('Maximum Difference Between OPT and ALG Allocations')\n",
    "\n",
    "sns.lineplot(x='Agent', y='value', hue='Algorithm', data=data_to_graph, style = 'Algorithm', dashes = dash_styles, ci = None)\n",
    "plt.title('Allocation Difference per Agent between OPT and ALG')\n",
    "plt.ylabel('Difference')\n",
    "plt.xlabel('Agent')\n",
    "plt.savefig('allocation.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
